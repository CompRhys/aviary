## Reproduction of Figures

NOTE: the archive files described are not yet publicly available.

Three addition sets of data are provided in the `datasets.tar.gz`, `results.tar.gz` and various sets of pre-trained models `figure-2.tar.gz`, `figure-3.tar.gz`, `figure-4_5.tar.gz`, and `combined.tar.gz`. Please unzip these and place the contents in `datasets`, `results/` and `models/pre-trained/` respectively. The `results/` and `models/` directories should have been automatically generated by running the above examples.

The in order to have the files in the correct places to reproduce the results using the given commands please ensure that the directory structure is as follows:

```txt
├── aviary
├── cds3
│   ├── array-run-gpu
│   ├── chemsys-expt.txt
│   ├── taata-expt.txt
│   └── wbm-expt.txt
├── data
│   ├── datasets
│   │   ├── chemsys
│   │   ├── comb
│   │   ├── examples
│   │   ├── mp
│   │   ├── taata
│   │   ├── wbm
│   │   └── wbm-ehull
│   ├── el-embeddings
│   └── wp-embeddings
├── environment-gpu-cu111.yml
├── examples
├── LICENSE
├── models
│   └── pre-trained
│       ├── cgcnn-taata-c_s-0_t-1
│       ├── chemsys-mp_s-0_t-1
│       ├── comb_s-0_t-1
│       ├── roost-taata-c_s-0_t-1
│       ├── wren-mp_s-0_t-1
│       └── wren-taata-c_s-0_t-1
├── README.md
├── results
│   └── manuscript
```

### Figure 2

Figure 2 is a direct comparison of different classes of model. We compare results from `roost`, `wren` on pre-relaxation inputs, and `cgcnn` on both pre and post-relaxation inputs. This figure demonstrates how the proposed Wyckoff representation can differentiate polymorphs and can be used to screen unrelaxed inputs without significant degradation in performance.

The data needed to reproduce Figure 2 of the manuscript are provided under `datasets/taata`.
The `cds3/taata-expt.txt` folder provides the `slurm` submit scripts and CLI inputs for all experiments as well as the CLI inputs to generate the results files.
To facilitate the reproduction of the Figures without having to re-run the ensembles for the different models we provide the necessary results files under `results/manuscript/` and pre-trained models under `models/pre-trained/`.
The Figure can be generated by running the `examples/plots/multi-pred-test-taata-hull.py` script.

### Figure 3

Figure 3 looks at whether we can use a model trained on the complement of a chemical system (i.e. all available data apart from data in that system) to identify the low lying phases more quickly than via the standard prototype-based high-throughput screening approach. To train the model we take the MP data set and exclude all tertiary systems in the `Hf-N-Zn`, `N-Ti-Zn` and `N-Zn-Zr` chemical systems. The enrichment plot shows that the model is capable of zero-shot generalisation to new chemical systems. Importantly we see that the model enriches lower energy structures more strongly which is exactly the behaviour we would desire in practice.

The data needed to reproduce Figure 3 of the manuscript are provided under `datasets/chemsys`.
The `cds3/chemsys-expt.txt` folder provides the `slurm` submit scripts and CLI inputs for all experiments as well as the CLI inputs to generate the results files.
To facilitate the reproduction of the Figures without having to re-run the ensembles for the different models we provide the necessary results files under `results/manuscript/` and pre-trained models under `models/pre-trained/`.
The Figure can be generated by running the `examples/plots/enrich-taata.py` script.

### Figures 4 and 5

Figures 4 and 5 look at a simulated materials discovery campaign. Here we make use of two independent data sources, the MP and WBM data sets, that have been prepared using the same DFT settings. The fact that they use the same DFT settings ensures that there is no covariate shift, this can be an issue when using data from different sources. Figure 4 highlights the strong recall that the Wren model achieves ~75%. Figure 5 highlights the shortcomings of using structure-based models to screen pre-relaxation inputs seen in the low accuracy of the model.

The data needed to reproduce Figures 4 and 5 of the manuscript are provided under `datasets/mp` and `datasets/wbm`.
The `cds3/wbm-expt.txt` folder provides the `slurm` submit scripts and CLI inputs for all experiments as well as the CLI inputs to generate the results files.
To facilitate the reproduction of the Figures without having to re-run the ensembles for the different models we provide the necessary results files under `results/manuscript/` and pre-trained models under `models/pre-trained/`.
For Figures 4 and 5 as we need to compute the distance to the convex hull of the MP training set we also provide this data pre-computed for the WBM splits - calculation of the energy of the hull at each of the compositions in the WBM data set requires the construction of ~48k convex hulls to get the energies for candidates overlapping the MP chemical systems, for candidates that do not overlap the MP chemical system the energy is calculated using a linear algebra approach calculated using `pymatgen.analysis.phase_diagram._get_slsqp_decomp`.
Figure 4 can be generated by running the `examples/plots/hist_clf.py` script and Figure 5 can be generated by running the `examples/plots/moving-mae-multi.py` script.

### Applying The Combined MP+WBM Model To Your Own Data

In order to apply the model to your own data the easiest approach will be to edit the `examples/inputs/poscar2df.py` script based on your needs. In the case that the target variable is unknown, e.g. prospective screening, the model will require the column to be filled with a placeholder i.e. `42`. An example is provided below:

| material_id | composition | E_f | wyckoff                       |
| ----------- | ----------- | --- | ----------------------------- |
| test-1      | Hf          | 42  | A_hP2_194_c:Hf                |
| test-2      | Hf(ZnN2)3   | 42  | AB6C3_hR30_160_a_2b_b:Hf-N-Zn |
| test-3      | Hf(ZnN2)3   | 42  | AB6C3_hR30_148_a_f_bc:Hf-N-Zn |

After generating a test file and correctly placing the pre-trained models you can produce predictions using:

```sh
python examples/wren.py --data-id pre-trained/comb --ensemble 10 --evaluate --data-path datasets/examples/examples.csv --test-path <path/to/your/input.csv> --targets E_f --tasks regression --losses L1 --robust
```

The `data-path` to `datasets/examples/examples.csv` is used as a placeholder that is needed given the current structure of the code.

## Notes

Some of the data files were originally prepared using an older input format, we have converted these inputs into the newer format based on the AFLOW prototype schema. However, in datasets that have been converted the Pearson symbol is filled by the string "pearson" as a placeholder. The Pearson symbol is not used by the __Wren__ model therefore this does not affect model performance.
