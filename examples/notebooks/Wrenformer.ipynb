{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from torch import __version__ as TORCH_VERSION\n",
    "\n",
    "print(f\"{TORCH_VERSION=}\")\n",
    "\n",
    "!pip install -U git+https://github.com/CompRhys/aviary.git  # install aviary\n",
    "!wget -O taata.json.gz https://figshare.com/ndownloader/files/34423997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pymatgen.analysis.prototypes import (\n",
    "    count_wyckoff_positions,\n",
    "    get_protostructure_label_from_spglib,\n",
    ")\n",
    "from pymatgen.core import Structure\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "from aviary.utils import results_multitask, train_ensemble\n",
    "from aviary.wrenformer.data import collate_batch as wrenformer_cb\n",
    "from aviary.wrenformer.data import df_to_in_mem_dataloader\n",
    "from aviary.wrenformer.model import Wrenformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n",
      "spglib: ssm_get_exact_positions failed.\n",
      "spglib: get_bravais_exact_positions_and_lattice failed.\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"taata.json.gz\", \"r\") as fin:\n",
    "    json_bytes = fin.read()\n",
    "\n",
    "json_str = json_bytes.decode(\"utf-8\")\n",
    "data = json.loads(json_str)\n",
    "\n",
    "df = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
    "\n",
    "df[\"final_structure\"] = [Structure.from_dict(x) for x in df.final_structure]\n",
    "\n",
    "df[\"composition\"] = [x.composition.reduced_formula for x in df.final_structure]\n",
    "df[\"volume_per_atom\"] = [x.volume / len(x) for x in df.final_structure]\n",
    "df[\"wyckoff\"] = df[\"final_structure\"].map(get_protostructure_label_from_spglib)\n",
    "\n",
    "df = df[df.wyckoff.map(count_wyckoff_positions) < 16]\n",
    "df[\"n_sites\"] = df.final_structure.map(len)\n",
    "df = df[df.n_sites < 64]\n",
    "df = df[df.volume_per_atom < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "fine_tune = None\n",
    "transfer = None\n",
    "\n",
    "optim = \"AdamW\"\n",
    "learning_rate = 3e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-6\n",
    "batch_size = 128\n",
    "workers = 0\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "targets = [\"E_vasp_per_atom\"]\n",
    "tasks = [\"regression\"]\n",
    "losses = [\"L1\"]\n",
    "robust = True\n",
    "\n",
    "data_seed = 42\n",
    "test_size = 0.2\n",
    "sample = 1\n",
    "\n",
    "ensemble = 1\n",
    "run_id = 1\n",
    "epochs = 3\n",
    "log = False\n",
    "\n",
    "# NOTE setting workers to zero means that the data is loaded in the main\n",
    "# process and enables caching\n",
    "\n",
    "data_params = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": workers,\n",
    "    \"pin_memory\": False,\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "\n",
    "setup_params = {\n",
    "    \"optim\": optim,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"momentum\": momentum,\n",
    "    \"device\": device,\n",
    "}\n",
    "\n",
    "restart_params = {\n",
    "    \"resume\": resume,\n",
    "    \"fine_tune\": fine_tune,\n",
    "    \"transfer\": transfer,\n",
    "}\n",
    "\n",
    "task_dict = dict(zip(targets, tasks, strict=False))\n",
    "loss_dict = dict(zip(targets, losses, strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 0.2 of training set as test set\n",
      "No validation set used, using test set for evaluation purposes\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_ensemble() got an unexpected keyword argument 'train_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 60\u001b[0m\n\u001b[1;32m     42\u001b[0m n_targets \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m train_df[target_col]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m target_col, task_type \u001b[38;5;129;01min\u001b[39;00m task_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     45\u001b[0m ]\n\u001b[1;32m     47\u001b[0m model_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: task_dict,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobust\u001b[39m\u001b[38;5;124m\"\u001b[39m: robust,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_aggregations\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m     58\u001b[0m }\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtrain_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWrenformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensemble_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43msetup_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestart_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m df_to_in_mem_dataloader(\n\u001b[1;32m     76\u001b[0m     test_df,\n\u001b[1;32m     77\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     78\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_loader_kwargs,\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m roost_results_dict \u001b[38;5;241m=\u001b[39m results_multitask(\n\u001b[1;32m     83\u001b[0m     model_class\u001b[38;5;241m=\u001b[39mWrenformer,\n\u001b[1;32m     84\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     save_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: train_ensemble() got an unexpected keyword argument 'train_loader'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  # ensure reproducible results\n",
    "\n",
    "input_col = \"wyckoff\"\n",
    "embedding_type = \"wyckoff\"\n",
    "model_name = \"wrenformer-reg-test\"\n",
    "\n",
    "data_params[\"collate_fn\"] = wrenformer_cb\n",
    "data_params[\"shuffle\"] = True\n",
    "\n",
    "print(f\"using {test_size} of training set as test set\")\n",
    "train_df, test_df = split(df, random_state=data_seed, test_size=test_size)\n",
    "\n",
    "print(\"No validation set used, using test set for evaluation purposes\")\n",
    "# NOTE that when using this option care must be taken not to\n",
    "# peak at the test-set. The only valid model to use is the one\n",
    "# obtained after the final epoch where the epoch count is\n",
    "# decided in advance of the experiment.\n",
    "val_df = test_df\n",
    "\n",
    "data_loader_kwargs = dict(\n",
    "    id_col=\"material_id\",  # TODO this should take a list of columns\n",
    "    input_col=input_col,\n",
    "    target_col=targets[0],  # TODO this should take a list of columns\n",
    "    embedding_type=embedding_type,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "train_loader = df_to_in_mem_dataloader(\n",
    "    train_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    **data_loader_kwargs,\n",
    ")\n",
    "\n",
    "val_loader = df_to_in_mem_dataloader(\n",
    "    test_df,\n",
    "    batch_size=batch_size * 16,\n",
    "    shuffle=False,\n",
    "    **data_loader_kwargs,\n",
    ")\n",
    "\n",
    "n_targets = [\n",
    "    1 if task_type == \"regression\" else train_df[target_col].max() + 1\n",
    "    for target_col, task_type in task_dict.items()\n",
    "]\n",
    "\n",
    "model_params = {\n",
    "    \"task_dict\": task_dict,\n",
    "    \"robust\": robust,\n",
    "    \"n_targets\": n_targets,\n",
    "    \"n_features\": train_loader.tensors[0][0].shape[-1],\n",
    "    \"d_model\": 128,\n",
    "    \"n_attn_layers\": 6,\n",
    "    \"n_attn_heads\": 4,\n",
    "    \"trunk_hidden\": (1024, 512),\n",
    "    \"out_hidden\": (256, 128, 64),\n",
    "    \"embedding_aggregations\": (\"mean\",),\n",
    "}\n",
    "\n",
    "train_ensemble(\n",
    "    model_class=Wrenformer,\n",
    "    model_name=model_name,\n",
    "    run_id=run_id,\n",
    "    ensemble_folds=ensemble,\n",
    "    epochs=epochs,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    log=log,\n",
    "    setup_params=setup_params,\n",
    "    restart_params=restart_params,\n",
    "    model_params=model_params,\n",
    "    loss_dict=loss_dict,\n",
    ")\n",
    "\n",
    "test_loader = df_to_in_mem_dataloader(\n",
    "    test_df,\n",
    "    batch_size=batch_size * 64,\n",
    "    shuffle=False,\n",
    "    **data_loader_kwargs,\n",
    ")\n",
    "\n",
    "roost_results_dict = results_multitask(\n",
    "    model_class=Wrenformer,\n",
    "    model_name=model_name,\n",
    "    run_id=run_id,\n",
    "    ensemble_folds=ensemble,\n",
    "    test_loader=test_loader,\n",
    "    robust=robust,\n",
    "    task_dict=task_dict,\n",
    "    device=device,\n",
    "    eval_type=\"checkpoint\",\n",
    "    save_results=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8022b3e932e045c760cb4633b91dd1cb8bc60d104ca9808334cbd1645adbe837"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
